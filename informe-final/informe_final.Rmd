---
title: "Informe Final"
author: "JHJ"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval=TRUE)
load("simulacions.RData")
library(sn) # skew normal
library(tidyverse)
library(gtsummary)
library(ggplot2)
library(patchwork)
library(lmtest)

simulacions.res = mutate(simulacions, 
                         l_mida = log(mida), 
                         l_bubblesort = log(bubblesort), 
                         l_quicksort = log(quicksort), 
                         l_mergesort = log(mergesort))

confidence.intervals = function(mostra, normalitat = FALSE, t.student = FALSE) {
  # si assumim normalitat apliquem la t-student
  if (normalitat) {
    if (t.student) {
      sort(mean(mostra) + qt(.025,length(mostra)-1) * c(-1,1) * sd(mostra) / sqrt(length(mostra)))
    } else {
      c(qnorm(.025, mean = mean(mostra), sd = sd(mostra)/(sqrt(length(mostra)))), 
        qnorm(.975, mean = mean(mostra), sd = sd(mostra)/(sqrt(length(mostra)))))
    }
  } else {
    # si no fem servir el mètode de bootstrap
    res = replicate(length(mostra), mean(sample(mostra,length(mostra), replace = TRUE)))
    quantile(res, c(.025,.975))
  }
}
histograma = function(m) {
  aux = mutate(simulacions, residus = residuals(m))
  ggplot(data = aux) +
    geom_histogram(aes(x = residus, y = after_stat(density))) + 
    geom_function(aes(col = 'Normal'), linewidth = 1, 
                  fun = function(x) dnorm(x, mean(aux$residus), sd(aux$residus))) + 
    geom_function(aes(col = 'Uniforme'), linewidth = 1, 
                  fun = function(x) dunif(x, min = min(aux$residus), max = max(aux$residus)))
}
histograma2 = function(residus) {
  ggplot() +
    geom_histogram(aes(x = residus, y = after_stat(density))) +  
    geom_function(aes(col = 'Skew Normal(alpha = -4)'), linewidth = 1, 
                  fun = function(x) dsn(x, xi = mean(residus), omega = sd(residus), -4)) + 
    geom_function(aes(col = 'Skew Normal(alpha = 0)'), linewidth = 1, 
                  fun = function(x) dsn(x, xi = mean(residus), omega = sd(residus), 0)) +
    geom_function(aes(col = 'Skew Normal(alpha = 4)'), linewidth = 1, 
                  fun = function(x) dsn(x, xi = mean(residus), omega = sd(residus), 4))
}
calcul.arrel = function(x) {
  sqrt(abs(x))
}
veure.tendencia = function(x) {
  suavitza = with(simulacions.res, lowess(mida, calcul.arrel(x)))
  ggplot(data = simulacions.res) +
    geom_point(aes(x = mida, y = calcul.arrel(x)), alpha = 0.05) +
    geom_line(data = as_tibble(suavitza), aes(x=x,y=y), col = 'blue') + 
    scale_x_continuous(trans = "log10") + 
    scale_y_continuous(trans = "log10")
}
```

# Introducció

La pregunta inicial era: Quin algoritme d'ordenació és millor? Nosaltres la vam transformar en quin algoritme d'ordenació és més eficaç? Entenent eficacia com l'eficiència dels algoritmes, o sigui, quin algoritme d'ordenació és més eficient?

La següent i principal pregunta és quina és la forma dels errors?

# Descriptiva de les dades

## Resum estadístic

  El nostre conjunt de dades es compon de dues taules, una conté informació de cadascun dels algoritmes que hem estudiat, (`algoritmes`).

```{r, echo=FALSE}
algoritmes
```

I una altra que conté informació del temps que ha trigat cada simulació amb cada algoritme, amb vectors de mides diferents, (`simulacions`), i podem descriure cada temps d'execució fent ser `summary()`.

```{r, echo=FALSE}
summary(select(simulacions.res, mida, l_mida, bubblesort, quicksort, mergesort, ord.bubblesort, ord.quicksort, ord.mergesort, l_bubblesort, l_quicksort, l_mergesort))
```

D'aquí podem començar a respondre a la **pregunta inicial**. I podem dir que el **quicksort** és l'únic algoritme que **empitjora amb vectors ordenats el temps d'execució (en mitjana)**, mentre que **bubblesort** i **mergesort**, **milloren el temps d'execució amb vectors ordenats**. Per tant, **el millor algoritme seria aquell que** amb vectors ordenats millora o iguala la mitjana del temps, *obtinguda amb vectors desordenats*, o que manté la forma del temps, és a dir, **que és estables**.

Això mirant la mitjana, però també podríem mirar altres estadístics del `summary`. I també podria ser útil veure quina és la correlació entre el temps d'execució i la mida del vector.

```{r, echo=FALSE}
tibble(
  bubblesort = cor(simulacions.res$mida, simulacions.res$bubblesort), 
  quicksort = cor(simulacions.res$mida, simulacions.res$quicksort), 
  mergesort = cor(simulacions.res$mida, simulacions.res$mergesort), 
  ord.bubblesort = cor(simulacions.res$mida, simulacions.res$ord.bubblesort), 
  ord.quicksort = cor(simulacions.res$mida, simulacions.res$ord.quicksort), 
  ord.mergesort = cor(simulacions.res$mida, simulacions.res$ord.mergesort)
)
```

I veiem que la variable dependent, **temps d'execució**, **té una correlació molt alta amb la variable independent, mida**.

## Visualització de dades

### Temps d'execució amb vectors ordenats i desordenats

Allò que hem dit de paraula, es veu millor si intentem veure-ho, visualitzant els temps de cada algoritme amb **vectors desordenats** i **vectors ordenats** amb un gràfic.

D'aquesta manera, podem veure **quina forma segueixen els temps d'execució de cada algoritme amb vectors ordenats i desordenats**, i podrem saber quin algoritme sembla més estable, és a dir, que manté la forma del temps, i a més també podrem veure la relació entre el temps d'execució i la mida del vector.

#### {.tabset}

##### BubbleSort _desordenat_

```{r, echo=FALSE}
ggplot(data = simulacions) +
  geom_point(aes(y = mida, x = bubblesort))
```

##### QuickSort _desordenat_

```{r, echo=FALSE}
ggplot(data = simulacions) +
  geom_point(aes(y = mida, x = quicksort))
```

##### MergeSort _desordenat_

```{r, echo=FALSE}
ggplot(data = simulacions) +
  geom_point(aes(y = mida, x = mergesort))
```

##### BubbleSort _ordenat_

```{r, echo=FALSE}
ggplot(data = simulacions) +
  geom_point(aes(y = mida, x = ord.bubblesort))
```

##### QuickSort _ordenat_

```{r, echo=FALSE}
ggplot(data = simulacions) +
  geom_point(aes(y = mida, x = ord.quicksort))
```

##### MergeSort _ordenat_

```{r, echo=FALSE}
ggplot(data = simulacions) +
  geom_point(aes(y = mida, x = ord.mergesort))
```

#### {.end}

I podem veure que **bubblesort** i **mergesort** mantenen la forma amb els dos tipus de vectors, mentre **quicksort** amb **vectors desordenats es comporta com el mergesort**, i amb **vectors ordenats es comporta com el bubblesort**. Això té relació amb l'explicat a altres assignatures de programació com $MTP_{1 \lor 2} \lor EDA$.

A partir d'aquí ja hem respost la pregunta de quin algoritme sembla millor, *o més eficient*, en aquest cas **quicksort sembla millor**, però **mergesort és més estable**, és a dir, mergesort manté la forma del temps, **bubblesort també manté la forma**, però és de la forma $n^2$, mentre que **mergesort** és $n \cdot log(n)$.

# Hipòtesi plantejada

A continuació, ajustarem els següents models que ens ajudaran a plantejar la següent pregunta del nostre estudi, **quina és la forma dels errors**, aquesta és la pregunta en la qual se centra la major part de l'estudi, per tant, ajustarem els models. *Els models que hem ajustat treballen amb el logaritme del temps d'execució*.

```{r, echo=FALSE}
mods.log = list(
  lm.bubblesort = lm(l_bubblesort~l_mida+I(l_mida^2), data = simulacions.res),  
  lm.quicksort = lm(l_quicksort~l_mida+I(l_mida*log(l_mida)), data = simulacions.res), 
  lm.mergesort = lm(l_mergesort~l_mida+I(l_mida*log(l_mida)), data = simulacions.res)
)
mods.log
```

I podem veure la forma dels errors, *o residus*, visualitzant-los amb l'histograma.

###  {.tabset}

#### BubbleSort

```{r, echo=FALSE, warning=FALSE}
histograma(mods.log$lm.bubblesort)
```

#### QuickSort

```{r, echo=FALSE, warning=FALSE}
histograma(mods.log$lm.quicksort)
```

#### MergeSort

```{r, echo=FALSE, warning=FALSE}
histograma(mods.log$lm.mergesort)
```

###  {.end}

La nostra **hipòtesi plantejada** és si **hi ha una relació entre els errors dels models i la mida del vector**, i **quina és la forma d'aquests errors**, *treballant amb el logaritme del temps*.

> I per tenir ordenats els contrastos els hi podem assignar un codi. p.e. `[contrast de normalitat]`, pel contrast de normalitat, i `[contrast d'homocedasticitat]` pel contrast d'homocedasticitat.

El primer contrast, és el `[contrast de normalitat]`, per contrastar la normalitat dels residus.

$$
H0: \text{Els residus són normals}\\
H1: \text{Els residus no són normals}
$$

I el segón, és el `[contrast d'homocedasticitat]`, per contrastar l'homocedasticitat dels residus.

$$
H0: \text{Els residus són homocedastics}\\
H1: \text{Els residus no són homocedastics}
$$

Per **respondre a la nostra hipòtesi també podem obtenir intervals de confiança**, i amb aquests intervals podem veure si **els residus són més normals**, o no, o si segueixen una certa forma.

**Utilitats:**

Per tal **construir intervals de confiança amb R**, hem programat la següent funció (`confidence.intervals`), que a partir d'una mostra, si no és pot assumir normalitat fa servir el **mètode de bootstrap**, altrament, si pot fer servir la **$t$-student**, la fa servir, altrament, fa servir el **teorema del límit central**. D'aquesta forma **el procés de construir intervals queda automatitzat en una funció**.

```{r, echo=FALSE}
confidence.intervals
```

> També tenim una funció per mostrar l'histograma, i altres funcions d'R que ens permeten automatitzar més tasques repetitives.

# Assumpcions seguides

L'assumpció més important que hem seguit, i que hem contrastat en el primer apartat d'aquest informe, és que la variable **temps** i la variable **mida**, **tenen una correlació molt alta**, i això és possible, ja que el **temps** s'ha obtingut a partir de vectors de diferents **mides**, o dit d'una altra manera, la variable **temps** és una variable dependent, i la variable **mida** és una variable independent.

Hem seguit altres assumpcions, p.e. relacionades amb el `[contrast de normalitat]`. Per tal d'estudiar els errors, com que **no podem assumir normalitat dels residus**, podem dir, pel **teorema del límit central**, almenys la nostra mostra és bastant gran.

```{r, echo=FALSE}
dim(simulacions.res)
```

Com que **la nostra mostra és bastant gran segons el teorema**, llavors podem assumir que **la mitjana de la mostra segueix una normal** com.

$$
\overline{X} \approx N(\mu_x, \frac{\sigma_x}{\sqrt{n}})
$$

Assumpcions del `[contrast d'homocedasticitat]`.

Altres assumpcions, hem vist que **no podem assumir una normal**, i tot i que **veient els gràfics ens pugui semblar que els residus són homoscedastics**, **tampoc tenim evidències per assumir l'homoscedasticitat dels residus**.

# Resultats i conclusió

Per donar resposta al contrast `[contrast de normalitat]`, podem fer servir la funció `shapiro.test()`.

```{r, echo=FALSE}
shapiro.test(residuals(mods.log$lm.bubblesort))
shapiro.test(residuals(mods.log$lm.quicksort))
shapiro.test(residuals(mods.log$lm.mergesort))
```

Amb un nivell de significació de $\alpha = 0.05$, podem veure que el $valor-p < \alpha$, per tant, **tenim evidències per rebutjar la normalitat dels residus**.

Per donar resposta al contrast `[contrast d'homocedasticitat]`, podem fer servir la funció `bptest()`, en aquest test no li passem els residus, sinó que li hem de passar els models directament.

```{r, echo=FALSE}
bptest(mods.log$lm.bubblesort)
bptest(mods.log$lm.quicksort)
bptest(mods.log$lm.mergesort)
```

Amb un nivell de significació de $\alpha = 0.05$, podem veure que el $valor-p < \alpha$, per tant, **tenim evidències per rebutjar l'homocedasticitat dels residus**. En conclusió, **els residus són heterocedastics**, és a dir, que segueixen una tendència.

Com que els resultats del `[contrast de normalitat]` i del `[contrast d'homocedasticitat]` ens han portat a rebutjar la hipòtesi nul·la, podem provar de construir intervals de confiança per veure si podem assumir algun contrast.

Aquests intervals els podem construir fent servir la funció `confidence.intervals()`, i com que no podem assumir normalitat dels residus, haurem de fer servir el mètode de bootstrap, és a dir, executar la funció `confidence.intervals(residus)`, canviant els residus pels residus dels models.

```{r, echo=FALSE}
int = tibble(
  bubblesort = confidence.intervals(residuals(mods.log$lm.bubblesort)), 
  quicksort = confidence.intervals(residuals(mods.log$lm.quicksort)), 
  mergesort = confidence.intervals(residuals(mods.log$lm.mergesort))
)
int
```

I tornem a contrastar `[contrast de normalitat]` i `[contrast d'homocedasticitat]` amb les funcions `shapiro.test()` i `bptest()` respectivament.

```{r, echo=FALSE}
shapiro.test(residuals(mods.log$lm.bubblesort)[between(residuals(mods.log$lm.bubblesort), int$bubblesort[1], int$bubblesort[2])])
shapiro.test(residuals(mods.log$lm.quicksort)[between(residuals(mods.log$lm.quicksort), int$quicksort[1], int$quicksort[2])])
shapiro.test(residuals(mods.log$lm.mergesort)[between(residuals(mods.log$lm.mergesort), int$mergesort[1], int$mergesort[2])])
```

Treballant amb el mateix nivell de significació ($\alpha = 0.05$). El $valor-p < \alpha$, per tant, continuem sense poder assumir normalitat dels residus.

I no podem respondre el `[contrast d'homocedasticitat]`, ja que a la funció `bptest()` li pasem els models ajustats, de totes maneres si no podem homocedasticitat ni normalitat, els intervals de confiança no ens aporten res de nou.

## Anàlisi de resultats

El `[contrast de normalitat]` i el `[contrast d'homocedasticitat]` ens han donat un $valor-p < \alpha$, on $\alpha = 0.05$. Per tant, no podem assumir normalitat dels residus, i els intervals de confiança tampoc ens aporten res de nou, per tant, podem dir que els residus dels models ajustats no són normals. Sí que podem dir que la mitjana segueix una normal, **pel teorema del límit central**.

I tot i que el `[contrast d'homocedasticitat]` ens diu que els residus no són homocedastics, en realitat **ho semblen bastant**.

###  {.tabset}

#### BubbleSort *desordenat*

```{r, echo=FALSE}
veure.tendencia(residuals(mods.log$lm.bubblesort))
```

#### QuickSort *desordenat*

```{r, echo=FALSE}
veure.tendencia(residuals(mods.log$lm.quicksort))
```

#### MergeSort *desordenat*

```{r, echo=FALSE}
veure.tendencia(residuals(mods.log$lm.mergesort))
```

###  {.end}

Finalment, observant els gràfics veiem que no semblen seguir cap tendència, tot i que el test d'homocedasticitat ens dona un $valor-p < \alpha$. Potser en aquest test devem estar veient un **error tipus 1**, rebutjar $H_0$ quan és certa, en tot cas hauríem de calcular la $P(\text{rebutjar }H_0 | H_0\text{ és certa})$.

I a partir d'aquí, podem pensar que els errors es poden ajustar a una `skew normal`.

###  {.tabset}

#### BubbleSort *desordenat*

```{r, echo=FALSE, warning=FALSE}
histograma2(residuals(mods.log$lm.bubblesort))
```

#### QuickSort *desordenat*

```{r, echo=FALSE, warning=FALSE}
histograma2(residuals(mods.log$lm.quicksort))
```

#### MergeSort *desordenat*

```{r, echo=FALSE, warning=FALSE}
histograma2(residuals(mods.log$lm.mergesort))
```

###  {.end}

I per acabar, podem arribar a la conclusió de què **els residus dels diferents models segueixen una skew normal amb $\alpha \pm 4$**.

## Conclusió

> Finalment, la conclusió final és que els residus dels temps dels diferents algoritmes estudiats segueixen la forma que han de seguir segons la teoria, p.e. bubblesort és $O(n^2)$ és el que aplicant la transformació logarítmica sembla seguir més una normal, mentre que el quicksort i el mergesort amb la forma $O(n \cdot log(n))$ segueixen més el logaritme que una normal. I quan diem que el bubblesort segueix una normal, en realitat volem dir que segueix una normal amb un biaix cap al 0, _cap a l'esquerra_, o una skew normal amb $\alpha \pm 4$, encara que tampoc semblen seguir aquesta distribució. En realitat els residus segueixen el logaritme, a conseqüència de la transformació logarítmica dels temps, que hem fet a l'inici de l'estudi.
>
> També és interessant que treballant amb el logaritme dels temps el test d'homoscedasticitat ens porta a rebutjar la hipòtesi nul·la, però veient els gràfics, veiem que els residus no semblen seguir cap tendència, és a dir, els residus semblen heterocedastics.

# Referències

- `[DiarisEstadistica]`. Grup JHJ. (2024). *Diaris d'estadistica*. Estadistica, GEINF, UdG.

- `[apuntsEstadistica]` Professors d'estadistica. (2024). *Apunts del moodle*. Estadistica, GEINF, UdG.

- `[apuntsEDA]` Professors de EDA. (2023). *Apunts del moodle de EDA*. EDA, GEINF, UdG.

- `[apuntsMTP]` Professors de $MTP_{1 \lor 2}$. (2022). *Apunts del moodle de MTP1 i MTP2*. $MTP_{1 \lor 2}$, GEINF, UdG.
